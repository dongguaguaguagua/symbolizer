{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f98b8e55-c347-4d46-9839-a3730c64cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e6487c-7427-4201-b47a-b7eaf22d5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37cdd558-6e91-4487-ad69-6ef67c4f0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "\n",
    "    return dict\n",
    "def load_data(data_path):\n",
    "    data = unpickle(data_path)\n",
    "    # print(data.keys())\n",
    "    _data = np.array(data[\"data\"])\n",
    "    _labels = np.array(data[\"labels\"])\n",
    "    print(\"data loaded.\")\n",
    "    return _data, _labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233758a8-dd70-43a6-a4e6-d36684bda2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels,\n",
    "            kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # shortcut（当通道数或 stride 不一致时）\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = ResidualBlock(3, 32)\n",
    "        self.layer2 = ResidualBlock(32, 64)\n",
    "        self.layer3 = ResidualBlock(64, 128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.layer1(x))   # 32×32 → 16×16\n",
    "        x = self.pool(self.layer2(x))   # 16×16 → 8×8\n",
    "        x = self.pool(self.layer3(x))   # 8×8 → 4×4\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def get_accuracy(model, loader, topk=1):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.topk(outputs.data, topk, dim=1)\n",
    "            total += labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if labels[i] in predicted[i]:\n",
    "                    correct += 1\n",
    "    return correct / total\n",
    "\n",
    "def train_one_epoch(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_model(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= total\n",
    "    test_accuracy = correct / total\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c0756-4e13-4935-b21e-46e35b0cf881",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0cc9bc-cc85-4981-954e-cf866bd25b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded.\n"
     ]
    }
   ],
   "source": [
    "# 读取原始数据\n",
    "data, labels = load_data(\"HASYv2\")\n",
    "labels = labels.squeeze(1)\n",
    "\n",
    "data = np.transpose(data, (3, 2, 0, 1))\n",
    "data = torch.from_numpy(data).float()\n",
    "labels = torch.from_numpy(labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9f21baa-86af-4a47-a7f1-d1f559adc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取增强数据\n",
    "ckpt = torch.load(\"HASYv2_balanced_500.pt\", map_location=\"cpu\")\n",
    "\n",
    "data = ckpt[\"data\"]\n",
    "labels = ckpt[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eeb69f5-fe69-4a47-be92-e3a192ff5f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([398626, 3, 32, 32])\n",
      "torch.Size([398626])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1db32df-4996-41e0-b024-1a14adf07021",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "splitter = StratifiedShuffleSplit(\n",
    "    n_splits=1,\n",
    "    test_size=0.2,\n",
    "    random_state=114\n",
    ")\n",
    "\n",
    "train_idx, test_idx = next(splitter.split(np.zeros(len(labels_np)), labels_np))\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset  = Subset(dataset, test_idx)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06b283-019b-4f72-b06d-76caec4b20f7",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea08af1e-8d9f-4654-a999-70738e875ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4983/4983 [00:43<00:00, 115.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0779, Train Acc: 0.6953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.7288, Val Acc: 0.7729\n",
      "\n",
      "Epoch [2/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4983/4983 [00:43<00:00, 113.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6250, Train Acc: 0.7957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5884, Val Acc: 0.8064\n",
      "\n",
      "Epoch [3/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4983/4983 [00:44<00:00, 111.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5131, Train Acc: 0.8263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5257, Val Acc: 0.8267\n",
      "\n",
      "Epoch [4/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4983/4983 [00:44<00:00, 113.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4401, Train Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4981, Val Acc: 0.8338\n",
      "\n",
      "Epoch [5/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4983/4983 [00:42<00:00, 116.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3853, Train Acc: 0.8627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4901, Val Acc: 0.8354\n",
      "\n",
      "Epoch [6/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4983/4983 [00:43<00:00, 115.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3423, Train Acc: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4746, Val Acc: 0.8450\n",
      "\n",
      "Epoch [7/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4983/4983 [00:42<00:00, 116.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3078, Train Acc: 0.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4681, Val Acc: 0.8491\n"
     ]
    }
   ],
   "source": [
    "num_classes = 370\n",
    "num_epochs = 7\n",
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = SimpleCNN(num_classes).to(device)\n",
    "model = ResidualCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, criterion, optimizer, train_loader, device\n",
    "    )\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    val_loss, val_acc = validate_model(\n",
    "        model, criterion, test_loader, device\n",
    "    )\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf42d8-53ac-4bdb-a827-c80212ddf4a6",
   "metadata": {},
   "source": [
    "## 模型效果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66aa8490-9d92-4f67-a624-93b2d0bdacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491332814891002\n",
      "0.9521360660261395\n",
      "0.9740109876326418\n",
      "0.9833178636831147\n",
      "0.9879838446679878\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    print(get_accuracy(model, test_loader, topk=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb9356dd-ba87-4861-a578-30303afa425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-bucket accuracy:\n",
      "head (>=1000)          | classes: 369 | mean acc: 0.844\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_count = Counter(labels.tolist())\n",
    "\n",
    "def bucket_by_count(n):\n",
    "    if n >= 1000:\n",
    "        return \"head (>=1000)\"\n",
    "    elif n >= 200:\n",
    "        return \"mid (200-999)\"\n",
    "    elif n >= 50:\n",
    "        return \"tail (50-199)\"\n",
    "    else:\n",
    "        return \"extreme-tail (<50)\"\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "per_class_correct = Counter()\n",
    "per_class_total = Counter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels_batch in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        for y_true, y_pred in zip(labels_batch, preds):\n",
    "            y_true = int(y_true.item())\n",
    "            per_class_total[y_true] += 1\n",
    "            if y_true == int(y_pred.item()):\n",
    "                per_class_correct[y_true] += 1\n",
    "\n",
    "bucket_acc = {\n",
    "    \"head (>=1000)\": [],\n",
    "    \"mid (200-999)\": [],\n",
    "    \"tail (50-199)\": [],\n",
    "    \"extreme-tail (<50)\": []\n",
    "}\n",
    "\n",
    "for cls in per_class_total:\n",
    "    acc = per_class_correct[cls] / per_class_total[cls]\n",
    "    bucket = bucket_by_count(train_count[cls])\n",
    "    bucket_acc[bucket].append(acc)\n",
    "\n",
    "print(\"Per-bucket accuracy:\")\n",
    "for bucket, accs in bucket_acc.items():\n",
    "    if len(accs) == 0:\n",
    "        continue\n",
    "    print(\n",
    "        f\"{bucket:22s} | \"\n",
    "        f\"classes: {len(accs):3d} | \"\n",
    "        f\"mean acc: {sum(accs)/len(accs):.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffcf34c-b7db-45d6-a55f-b694ec8119b6",
   "metadata": {},
   "source": [
    "## 转成ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f42269fd-a8ea-4153-9608-c42bc3c02a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, 32, 32, device=device)\n",
    "\n",
    "import torch.onnx\n",
    "\n",
    "onnx_path = \"simplecnn_fp32.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=13,\n",
    "    do_constant_folding=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"logits\": {0: \"batch_size\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4920686-d9c4-42cb-889a-cd8e963b42a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting onnx\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/fb/71/d3fec0dcf9a7a99e7368112d9c765154e81da70fcba1e3121131a45c245b/onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ef/88/9cc25d2bafe6bc0d4d3c1db3ade98196d5b355c0b273e6a5dc09c5d5d0d5/onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime-tools\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/6f/b0/db0e73356df0aaa8737e6f13c0dac499b5d904d3fa267c8ebf24515e8001/onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in ./miniconda3/lib/python3.12/site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in ./miniconda3/lib/python3.12/site-packages (from onnx) (5.27.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in ./miniconda3/lib/python3.12/site-packages (from onnx) (4.12.1)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/3a/cb/28ce52eb94390dda42599c98ea0204d74799e4d8047a0eb559b6fd648056/ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e8/2d/d2a548598be01649e2d46231d151a6c56d10b964d94043a335ae56ea2d92/flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.12/site-packages (from onnxruntime) (23.2)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.12/site-packages (from onnxruntime) (1.12.1)\n",
      "Requirement already satisfied: psutil in ./miniconda3/lib/python3.12/site-packages (from onnxruntime-tools) (5.9.8)\n",
      "Collecting py-cpuinfo (from onnxruntime-tools)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting py3nvml (from onnxruntime-tools)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/03/3a/ea6f2419bd20f97f65ee55a9910c722313fe99cacc0bf77afb4b74b446ff/py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xmltodict (from py3nvml->onnxruntime-tools)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c0/20/69a0e6058bc5ea74892d089d64dfc3a62ba78917ec5e2cfa70f7c92ba3a5/xmltodict-1.0.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.12/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Installing collected packages: py-cpuinfo, flatbuffers, xmltodict, ml_dtypes, humanfriendly, py3nvml, onnx, coloredlogs, onnxruntime-tools, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.12.19 humanfriendly-10.0 ml_dtypes-0.5.4 onnx-1.20.1 onnxruntime-1.23.2 onnxruntime-tools-1.7.0 py-cpuinfo-9.0.0 py3nvml-0.2.7 xmltodict-1.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime onnxruntime-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "145cc6bc-2718-4b6e-bc2b-29bca50f962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from onnxruntime.quantization import CalibrationDataReader\n",
    "\n",
    "class CalibDataReader(CalibrationDataReader):\n",
    "    def __init__(self, dataloader, num_batches=10):\n",
    "        self.dataloader = dataloader\n",
    "        self.iterator = iter(dataloader)\n",
    "        self.num_batches = num_batches\n",
    "        self.count = 0\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.count >= self.num_batches:\n",
    "            return None\n",
    "        self.count += 1\n",
    "\n",
    "        inputs, _ = next(self.iterator)\n",
    "        return {\"input\": inputs.numpy()}\n",
    "\n",
    "calib_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "calib_reader = CalibDataReader(calib_loader, num_batches=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e42701a8-bb70-4996-b60c-747adc471c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_static, QuantType\n",
    "\n",
    "quant_onnx_path = \"residualcnn_augument_int8.onnx\"\n",
    "\n",
    "quantize_static(\n",
    "    model_input=onnx_path,\n",
    "    model_output=quant_onnx_path,\n",
    "    calibration_data_reader=calib_reader,\n",
    "    weight_type=QuantType.QInt8,\n",
    "    activation_type=QuantType.QUInt8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fe7d3-d743-4e3e-b82a-3e62c804b9e9",
   "metadata": {},
   "source": [
    "## ONNX推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00e447f7-bcfc-4aa4-910e-daed79afe6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX INT8 Acc: 0.8485061335072623\n"
     ]
    }
   ],
   "source": [
    "# ONNX推理\n",
    "import onnxruntime as ort\n",
    "\n",
    "sess = ort.InferenceSession(\n",
    "    quant_onnx_path,\n",
    "    providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "def onnx_infer(session, inputs):\n",
    "    ort_inputs = {\"input\": inputs.numpy()}\n",
    "    logits = session.run(None, ort_inputs)[0]\n",
    "    return logits\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    logits = onnx_infer(sess, inputs)\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    correct += (preds == labels.numpy()).sum()\n",
    "    total += labels.size(0)\n",
    "\n",
    "print(\"ONNX INT8 Acc:\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4bfa0466-aaaf-48ea-8481-4ec84d87a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in test_loader:\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d972657-714c-4ca5-aa89-d15e239bb4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ['batch_size', 3, 32, 32] tensor(float)\n"
     ]
    }
   ],
   "source": [
    "for i in sess.get_inputs():\n",
    "    print(i.name, i.shape, i.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbeff0-fb9f-48ae-9d73-14671068f324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
